# YouTube Recommendation Bias — My Research

## Article  
[Ibrahim, H., Aldahoul, N., Lee, S., Rahwan, T., et al. _YouTube’s recommendation algorithm is left-leaning in the United States_. _PNAS Nexus_, 2(8), 2023. DOI:10.1093/pnasnexus/pgad264](https://academic.oup.com/pnasnexus/article/2/8/pgad264/7242446) 

## What I Found Interesting  
- This work uses bots (archetypal users) spanning a spectrum of political personas (from Far Left to Far Right) to test how YouTube’s recommendation system behaves.  
- One of its key findings is that even users with **no watch history** still see a skew toward left‐leaning content in their baseline recommendations. 

## How I Used This in My Research  
In my project, I’m investigating the **effect of off-platform visits on Youtube's algorithm**, especially how recommendation systems might use your data collected by other sites. 
## Comments - Alisha Atif
I found the research on YouTube recommendation bias really interesting. The use of bots with different political personas makes the experiment feel systematic and convincing. It also connects with my own curiosity about how platforms use off site data to influence what we see on YouTube.

## Comments - Talal Naveed
I think this research is fascinating because it highlights how even a "neutral" new user can be nudged by algorithmic bias. The use of bots with distinct political personas adds credibility to the findings. It also ties nicely to your project since both explore how unseen mechanisms shape the content we’re shown.
